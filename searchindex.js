Search.setIndex({"docnames": ["index", "modules", "src"], "filenames": ["index.rst", "modules.rst", "src.rst"], "titles": ["Welcome to Neural Networks DIY\u2019s documentation!", "src", "src package"], "terms": {"index": 0, "modul": [0, 1], "pag": 0, "recherch": 0, "packag": 1, "submodul": 1, "activ": 1, "convolu": 1, "encapsul": 1, "linear": 1, "loss": 1, "content": [], "leakyrelu": [1, 2], "backward_delt": [1, 2], "backward_update_gradient": [1, 2], "forward": [1, 2], "update_parameter": [1, 2], "zero_grad": [1, 2], "logsoftmax": [1, 2], "relu": [1, 2], "sigmoid": [1, 2], "softmax": [1, 2], "softplus": [1, 2], "stablesigmoid": [1, 2], "tanh": [1, 2], "avgpool1d": [1, 2], "conv1d": [1, 2], "flatten": [1, 2], "maxpool1d": [1, 2], "optim": [1, 2], "sgd": [1, 2], "sgd_eval": [1, 2], "scor": [1, 2], "step": [1, 2], "sequential": [1, 2], "add": [1, 2], "backward": [1, 2], "insert": [1, 2], "reset": [1, 2], "bceloss": [1, 2], "celogsoftmax": [1, 2], "crossentropyloss": [1, 2], "mseloss": [1, 2], "calculate_gain": [1, 2], "class": 2, "alpha": 2, "0": 2, "01": 2, "sourc": 2, "bas": 2, "leaky": 2, "function": 2, "ext": [], "x": 2, "max": 2, "lpha": [], "egin": [], "cas": 2, "if": 2, "geq": 2, "ime": [], "otherwis": 2, "end": 2, "input": 2, "delt": 2, "calculat": 2, "the": 2, "deriv": 2, "of": 2, "error": 2, "and": 2, "next": 2, "with": 2, "respect": 2, "to": 2, "delta_j": 2, "h": 2, "1": 2, "rac": [], "partial": 2, "L": 2, "z_j": 2, "sum_k": 2, "z_k": 2, "let": 2, "abla_": [], "mathbf": 2, "z": 2, "left": 2, "array": 2, "ccc": 2, "z_1": 2, "z_2": 2, "cdot": 2, "ddot": 2, "dot": [], "ight": [], "updat": 2, "gradient": 2, "valu": 2, "given": 2, "w_i": 2, "delta_k": 2, "w": 2, "w_1": 2, "w_2": 2, "pass": 2, "learning_rat": 2, "parameter": 2, "according": 2, "calculated": 2, "learning": 2, "rat": 2, "r\u00e9initialis": 2, "x_": 2, "i": 2, "log": 2, "exp": 2, "x_i": 2, "sum_j": 2, "x_j": 2, "rectified": 2, "unit": 2, "math": [], "f": [], "else": 2, "sigm": 2, "smooth": 2, "approxim": 2, "ln": 2, "e": 2, "numerically": 2, "stabl": 2, "hyperbolic": 2, "tangent": 2, "anh": [], "k_siz": 2, "strid": 2, "1d": 2, "averag": 2, "pooling": 2, "parametr": 2, "int": 2, "siz": 2, "convolving": 2, "kernel": 2, "optional": 2, "default": 2, "ndarray": 2, "batch": 2, "length": 2, "chan_in": 2, "output": 2, "chan_out": 2, "bi": 2, "bool": 2, "fals": 2, "init_typ": 2, "str": 2, "xavier_normal": 2, "numb": 2, "channel": 2, "in": 2, "imag": 2, "produced": 2, "by": 2, "tru": 2, "a": 2, "learnabl": 2, "chang": 2, "initializ": 2, "weight": 2, "an": 2, "network": 2, "ep": 2, "float": 2, "object": 2, "batch_siz": 2, "epoch": 2, "non": 2, "shuffl": 2, "seed": 2, "test_siz": 2, "shuffle_train": 2, "shuffle_test": 2, "return_datafram": 2, "fig": [], "ax": [], "batch_x": 2, "batch_y": 2, "todo": [], "y_hat": [], "self": 2, "reshap": 2, "batchsiz": [], "Il": [], "faut": [], "fix": [], "brok": [], "multiclass": [], "8": 2, "2": 2, "16": [], "arg": 2, "idx": 2, "at": 2, "specified": 2, "indic": 2, "initial": 2, "001": 2, "input_siz": 2, "output_siz": 2, "normal": 2, "sampl": 2, "not": 1, "binary": 2, "cross": 2, "entropy": 2, "yhat": 2, "do": [], "CE": 2, "hat": 2, "_y": 2, "sum_": 2, "k": 2, "_i": 2, "mean": 2, "squared": 2, "mse": 2, "text": 2, "frac": 2, "right": 2, "begin": 2, "tim": 2, "nabla_": 2, "vdot": 2, "M": 2, "commonly": 2, "used": 2, "along": 2, "See": 2, "http": 2, "eli": 2, "thegreenplac": 2, "net": 2, "2016": 2, "it": 2, "www": 2, "parasdahal": 2, "com": 2, "crossentropy": 2, "plus": 2, "pr\u00e9cis": 2, "si": 2, "neq": 2, "implemented": 2, "using": 2, "sum": 2, "trick": 2, "avoid": 2, "nan": 2, "computing": 2, "numerical": 2, "stability": 2, "align": 2, "sinh": 2, "cosh": 2, "2x": 2, "literal": 2, "uniform": 2, "zeros": 2, "one": 2, "he_normal": 2, "he_uniform": 2, "xavier_uniform": 2, "42": 2, "patienc": 2, "10": 2, "online_plot": 2, "src": [], "tout": 0, "bordel": [], "dan": 0, "temp": [], "certain": [], "auss": [], "assez": [], "shap": 1, "exampl": 1, "we": 2, "tried": 2, "vectoriz": 2, "our": 2, "maximum": 2, "prioritizing": 2, "perform": 2, "impli": 2, "creating": 2, "special": 2, "view": 2, "numpy": 2, "lib": 2, "stride_trick": 2, "sliding_window_view": 2, "is": 2, "easiest": 2, "understand": 2, "whil": 2, "mayb": 2, "fastest": 2, "compared": 2, "as_strided": 2, "but": 2, "less": 2, "risky": 2, "too": 2, "calcul": 2, "are": 2, "don": 2, "np": 2, "einsum": 2, "which": 2, "relatively": 2, "easy": 2, "use": 2, "key": 2, "rel": 2, "understanding": 2, "your": 2, "remind": 2, "for": 2, "d_out": 2, "x_view": 2, "out_length": 2, "_gradient": 2, "_parameter": 2, "notat": 2, "b": 2, "width": 2, "2d": 2, "height": 2, "o": 2, "out_width": 2, "p": 2, "out_height": 2, "ij": 2, "quick": 2, "demonstr": 2, "3": 2, "random": 2, "randn": 2, "41982262": 2, "10111123": 2, "41115195": 2, "18733225": 2, "93463567": 2, "22472025": 2, "30581971": 2, "40578667": 2, "window": 2, "how": 2, "deal": 2, "then": 2, "just": 2, "matt": 2, "drop": 2, "unnecessar": 2, "dimens": 2, "g": 2, "voil\u00e0": 2, "automodul": [], "member": [], "undoc": [], "show": [], "inherit": [], "cod": 2, "block": 2, "python": 2, "param": [], "typ": []}, "objects": {"src": [[2, 0, 0, "-", "activation"], [2, 0, 0, "-", "convolution"], [2, 0, 0, "-", "encapsulation"], [2, 0, 0, "-", "linear"], [2, 0, 0, "-", "loss"], [2, 0, 0, "-", "module"]], "src.activation": [[2, 1, 1, "", "LeakyReLU"], [2, 1, 1, "", "LogSoftmax"], [2, 1, 1, "", "ReLU"], [2, 1, 1, "", "Sigmoid"], [2, 1, 1, "", "Softmax"], [2, 1, 1, "", "Softplus"], [2, 1, 1, "", "StableSigmoid"], [2, 1, 1, "", "TanH"]], "src.activation.LeakyReLU": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.activation.LogSoftmax": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.activation.ReLU": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.activation.Sigmoid": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.activation.Softmax": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.activation.Softplus": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.activation.StableSigmoid": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.activation.TanH": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.convolution": [[2, 1, 1, "", "AvgPool1D"], [2, 1, 1, "", "Conv1D"], [2, 1, 1, "", "Flatten"], [2, 1, 1, "", "MaxPool1D"]], "src.convolution.AvgPool1D": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.convolution.Conv1D": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.convolution.Flatten": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.convolution.MaxPool1D": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.encapsulation": [[2, 1, 1, "", "Optim"], [2, 1, 1, "", "Sequential"]], "src.encapsulation.Optim": [[2, 2, 1, "", "SGD"], [2, 2, 1, "", "SGD_eval"], [2, 2, 1, "", "score"], [2, 2, 1, "", "step"]], "src.encapsulation.Sequential": [[2, 2, 1, "", "add"], [2, 2, 1, "", "backward"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "insert"], [2, 2, 1, "", "reset"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.linear": [[2, 1, 1, "", "Linear"]], "src.linear.Linear": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]], "src.loss": [[2, 1, 1, "", "BCELoss"], [2, 1, 1, "", "CELogSoftmax"], [2, 1, 1, "", "CrossEntropyLoss"], [2, 1, 1, "", "MSELoss"]], "src.loss.BCELoss": [[2, 2, 1, "", "backward"], [2, 2, 1, "", "forward"]], "src.loss.CELogSoftmax": [[2, 2, 1, "", "backward"], [2, 2, 1, "", "forward"]], "src.loss.CrossEntropyLoss": [[2, 2, 1, "", "backward"], [2, 2, 1, "", "forward"]], "src.loss.MSELoss": [[2, 2, 1, "", "backward"], [2, 2, 1, "", "forward"]], "src.module": [[2, 1, 1, "", "Loss"], [2, 1, 1, "", "Module"]], "src.module.Loss": [[2, 2, 1, "", "backward"], [2, 2, 1, "", "forward"]], "src.module.Module": [[2, 2, 1, "", "backward_delta"], [2, 2, 1, "", "backward_update_gradient"], [2, 2, 1, "", "calculate_gain"], [2, 2, 1, "", "forward"], [2, 2, 1, "", "update_parameters"], [2, 2, 1, "", "zero_grad"]]}, "objtypes": {"0": "py:module", "1": "py:class", "2": "py:method"}, "objnames": {"0": ["py", "module", "Python module"], "1": ["py", "class", "Python classe"], "2": ["py", "method", "Python m\u00e9thode"]}, "titleterms": {"welcom": 0, "to": 0, "neural": 0, "network": 0, "diy": 0, "document": 0, "indic": 0, "and": 0, "tabl": 0, "src": [1, 2], "packag": 2, "submodul": 2, "activ": 2, "modul": 2, "convolu": 2, "encapsul": 2, "linear": 2, "loss": 2, "content": [], "shap": 2, "not": 2, "exampl": 2}, "envversion": {"sphinx.domains.c": 2, "sphinx.domains.changeset": 1, "sphinx.domains.citation": 1, "sphinx.domains.cpp": 8, "sphinx.domains.index": 1, "sphinx.domains.javascript": 2, "sphinx.domains.math": 2, "sphinx.domains.python": 3, "sphinx.domains.rst": 2, "sphinx.domains.std": 2, "sphinx.ext.intersphinx": 1, "sphinx.ext.todo": 2, "sphinx.ext.viewcode": 1, "sphinx": 57}, "alltitles": {"src": [[1, "src"]], "Welcome to Neural Networks DIY\u2019s documentation!": [[0, "welcome-to-neural-networks-diy-s-documentation"]], "Indices and tables": [[0, "indices-and-tables"]], "src package": [[2, "src-package"]], "Submodules": [[2, "submodules"]], "src.activation module": [[2, "module-src.activation"]], "src.convolution module": [[2, "src-convolution-module"]], "Shape": [[2, "shape"], [2, "id1"], [2, "id2"], [2, "id3"], [2, "id4"], [2, "id5"]], "Notes": [[2, "notes"]], "Examples": [[2, "examples"]], "src.encapsulation module": [[2, "module-src.encapsulation"]], "src.linear module": [[2, "module-src.linear"]], "src.loss module": [[2, "module-src.loss"]], "src.module module": [[2, "module-src.module"]]}, "indexentries": {"avgpool1d (classe dans src.convolution)": [[2, "src.convolution.AvgPool1D"]], "bceloss (classe dans src.loss)": [[2, "src.loss.BCELoss"]], "celogsoftmax (classe dans src.loss)": [[2, "src.loss.CELogSoftmax"]], "conv1d (classe dans src.convolution)": [[2, "src.convolution.Conv1D"]], "crossentropyloss (classe dans src.loss)": [[2, "src.loss.CrossEntropyLoss"]], "flatten (classe dans src.convolution)": [[2, "src.convolution.Flatten"]], "leakyrelu (classe dans src.activation)": [[2, "src.activation.LeakyReLU"]], "linear (classe dans src.linear)": [[2, "src.linear.Linear"]], "logsoftmax (classe dans src.activation)": [[2, "src.activation.LogSoftmax"]], "loss (classe dans src.module)": [[2, "src.module.Loss"]], "mseloss (classe dans src.loss)": [[2, "src.loss.MSELoss"]], "maxpool1d (classe dans src.convolution)": [[2, "src.convolution.MaxPool1D"]], "module (classe dans src.module)": [[2, "src.module.Module"]], "optim (classe dans src.encapsulation)": [[2, "src.encapsulation.Optim"]], "relu (classe dans src.activation)": [[2, "src.activation.ReLU"]], "sgd() (m\u00e9thode src.encapsulation.optim)": [[2, "src.encapsulation.Optim.SGD"]], "sgd_eval() (m\u00e9thode src.encapsulation.optim)": [[2, "src.encapsulation.Optim.SGD_eval"]], "sequential (classe dans src.encapsulation)": [[2, "src.encapsulation.Sequential"]], "sigmoid (classe dans src.activation)": [[2, "src.activation.Sigmoid"]], "softmax (classe dans src.activation)": [[2, "src.activation.Softmax"]], "softplus (classe dans src.activation)": [[2, "src.activation.Softplus"]], "stablesigmoid (classe dans src.activation)": [[2, "src.activation.StableSigmoid"]], "tanh (classe dans src.activation)": [[2, "src.activation.TanH"]], "add() (m\u00e9thode src.encapsulation.sequential)": [[2, "src.encapsulation.Sequential.add"]], "backward() (m\u00e9thode src.encapsulation.sequential)": [[2, "src.encapsulation.Sequential.backward"]], "backward() (m\u00e9thode src.loss.bceloss)": [[2, "src.loss.BCELoss.backward"]], "backward() (m\u00e9thode src.loss.celogsoftmax)": [[2, "src.loss.CELogSoftmax.backward"]], "backward() (m\u00e9thode src.loss.crossentropyloss)": [[2, "src.loss.CrossEntropyLoss.backward"]], "backward() (m\u00e9thode src.loss.mseloss)": [[2, "src.loss.MSELoss.backward"]], "backward() (m\u00e9thode src.module.loss)": [[2, "src.module.Loss.backward"]], "backward_delta() (m\u00e9thode src.activation.leakyrelu)": [[2, "src.activation.LeakyReLU.backward_delta"]], "backward_delta() (m\u00e9thode src.activation.logsoftmax)": [[2, "src.activation.LogSoftmax.backward_delta"]], "backward_delta() (m\u00e9thode src.activation.relu)": [[2, "src.activation.ReLU.backward_delta"]], "backward_delta() (m\u00e9thode src.activation.sigmoid)": [[2, "src.activation.Sigmoid.backward_delta"]], "backward_delta() (m\u00e9thode src.activation.softmax)": [[2, "src.activation.Softmax.backward_delta"]], "backward_delta() (m\u00e9thode src.activation.softplus)": [[2, "src.activation.Softplus.backward_delta"]], "backward_delta() (m\u00e9thode src.activation.stablesigmoid)": [[2, "src.activation.StableSigmoid.backward_delta"]], "backward_delta() (m\u00e9thode src.activation.tanh)": [[2, "src.activation.TanH.backward_delta"]], "backward_delta() (m\u00e9thode src.convolution.avgpool1d)": [[2, "src.convolution.AvgPool1D.backward_delta"]], "backward_delta() (m\u00e9thode src.convolution.conv1d)": [[2, "src.convolution.Conv1D.backward_delta"]], "backward_delta() (m\u00e9thode src.convolution.flatten)": [[2, "src.convolution.Flatten.backward_delta"]], "backward_delta() (m\u00e9thode src.convolution.maxpool1d)": [[2, "src.convolution.MaxPool1D.backward_delta"]], "backward_delta() (m\u00e9thode src.linear.linear)": [[2, "src.linear.Linear.backward_delta"]], "backward_delta() (m\u00e9thode src.module.module)": [[2, "src.module.Module.backward_delta"]], "backward_update_gradient() (m\u00e9thode src.activation.leakyrelu)": [[2, "src.activation.LeakyReLU.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.activation.logsoftmax)": [[2, "src.activation.LogSoftmax.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.activation.relu)": [[2, "src.activation.ReLU.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.activation.sigmoid)": [[2, "src.activation.Sigmoid.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.activation.softmax)": [[2, "src.activation.Softmax.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.activation.softplus)": [[2, "src.activation.Softplus.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.activation.stablesigmoid)": [[2, "src.activation.StableSigmoid.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.activation.tanh)": [[2, "src.activation.TanH.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.convolution.avgpool1d)": [[2, "src.convolution.AvgPool1D.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.convolution.conv1d)": [[2, "src.convolution.Conv1D.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.convolution.flatten)": [[2, "src.convolution.Flatten.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.convolution.maxpool1d)": [[2, "src.convolution.MaxPool1D.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.linear.linear)": [[2, "src.linear.Linear.backward_update_gradient"]], "backward_update_gradient() (m\u00e9thode src.module.module)": [[2, "src.module.Module.backward_update_gradient"]], "calculate_gain() (m\u00e9thode src.module.module)": [[2, "src.module.Module.calculate_gain"]], "forward() (m\u00e9thode src.activation.leakyrelu)": [[2, "src.activation.LeakyReLU.forward"]], "forward() (m\u00e9thode src.activation.logsoftmax)": [[2, "src.activation.LogSoftmax.forward"]], "forward() (m\u00e9thode src.activation.relu)": [[2, "src.activation.ReLU.forward"]], "forward() (m\u00e9thode src.activation.sigmoid)": [[2, "src.activation.Sigmoid.forward"]], "forward() (m\u00e9thode src.activation.softmax)": [[2, "src.activation.Softmax.forward"]], "forward() (m\u00e9thode src.activation.softplus)": [[2, "src.activation.Softplus.forward"]], "forward() (m\u00e9thode src.activation.stablesigmoid)": [[2, "src.activation.StableSigmoid.forward"]], "forward() (m\u00e9thode src.activation.tanh)": [[2, "src.activation.TanH.forward"]], "forward() (m\u00e9thode src.convolution.avgpool1d)": [[2, "src.convolution.AvgPool1D.forward"]], "forward() (m\u00e9thode src.convolution.conv1d)": [[2, "src.convolution.Conv1D.forward"]], "forward() (m\u00e9thode src.convolution.flatten)": [[2, "src.convolution.Flatten.forward"]], "forward() (m\u00e9thode src.convolution.maxpool1d)": [[2, "src.convolution.MaxPool1D.forward"]], "forward() (m\u00e9thode src.encapsulation.sequential)": [[2, "src.encapsulation.Sequential.forward"]], "forward() (m\u00e9thode src.linear.linear)": [[2, "src.linear.Linear.forward"]], "forward() (m\u00e9thode src.loss.bceloss)": [[2, "src.loss.BCELoss.forward"]], "forward() (m\u00e9thode src.loss.celogsoftmax)": [[2, "src.loss.CELogSoftmax.forward"]], "forward() (m\u00e9thode src.loss.crossentropyloss)": [[2, "src.loss.CrossEntropyLoss.forward"]], "forward() (m\u00e9thode src.loss.mseloss)": [[2, "src.loss.MSELoss.forward"]], "forward() (m\u00e9thode src.module.loss)": [[2, "src.module.Loss.forward"]], "forward() (m\u00e9thode src.module.module)": [[2, "src.module.Module.forward"]], "insert() (m\u00e9thode src.encapsulation.sequential)": [[2, "src.encapsulation.Sequential.insert"]], "module": [[2, "module-src.activation"], [2, "module-src.convolution"], [2, "module-src.encapsulation"], [2, "module-src.linear"], [2, "module-src.loss"], [2, "module-src.module"]], "reset() (m\u00e9thode src.encapsulation.sequential)": [[2, "src.encapsulation.Sequential.reset"]], "score() (m\u00e9thode src.encapsulation.optim)": [[2, "src.encapsulation.Optim.score"]], "src.activation": [[2, "module-src.activation"]], "src.convolution": [[2, "module-src.convolution"]], "src.encapsulation": [[2, "module-src.encapsulation"]], "src.linear": [[2, "module-src.linear"]], "src.loss": [[2, "module-src.loss"]], "src.module": [[2, "module-src.module"]], "step() (m\u00e9thode src.encapsulation.optim)": [[2, "src.encapsulation.Optim.step"]], "update_parameters() (m\u00e9thode src.activation.leakyrelu)": [[2, "src.activation.LeakyReLU.update_parameters"]], "update_parameters() (m\u00e9thode src.activation.logsoftmax)": [[2, "src.activation.LogSoftmax.update_parameters"]], "update_parameters() (m\u00e9thode src.activation.relu)": [[2, "src.activation.ReLU.update_parameters"]], "update_parameters() (m\u00e9thode src.activation.sigmoid)": [[2, "src.activation.Sigmoid.update_parameters"]], "update_parameters() (m\u00e9thode src.activation.softmax)": [[2, "src.activation.Softmax.update_parameters"]], "update_parameters() (m\u00e9thode src.activation.softplus)": [[2, "src.activation.Softplus.update_parameters"]], "update_parameters() (m\u00e9thode src.activation.stablesigmoid)": [[2, "src.activation.StableSigmoid.update_parameters"]], "update_parameters() (m\u00e9thode src.activation.tanh)": [[2, "src.activation.TanH.update_parameters"]], "update_parameters() (m\u00e9thode src.convolution.avgpool1d)": [[2, "src.convolution.AvgPool1D.update_parameters"]], "update_parameters() (m\u00e9thode src.convolution.conv1d)": [[2, "src.convolution.Conv1D.update_parameters"]], "update_parameters() (m\u00e9thode src.convolution.flatten)": [[2, "src.convolution.Flatten.update_parameters"]], "update_parameters() (m\u00e9thode src.convolution.maxpool1d)": [[2, "src.convolution.MaxPool1D.update_parameters"]], "update_parameters() (m\u00e9thode src.encapsulation.sequential)": [[2, "src.encapsulation.Sequential.update_parameters"]], "update_parameters() (m\u00e9thode src.linear.linear)": [[2, "src.linear.Linear.update_parameters"]], "update_parameters() (m\u00e9thode src.module.module)": [[2, "src.module.Module.update_parameters"]], "zero_grad() (m\u00e9thode src.activation.leakyrelu)": [[2, "src.activation.LeakyReLU.zero_grad"]], "zero_grad() (m\u00e9thode src.activation.logsoftmax)": [[2, "src.activation.LogSoftmax.zero_grad"]], "zero_grad() (m\u00e9thode src.activation.relu)": [[2, "src.activation.ReLU.zero_grad"]], "zero_grad() (m\u00e9thode src.activation.sigmoid)": [[2, "src.activation.Sigmoid.zero_grad"]], "zero_grad() (m\u00e9thode src.activation.softmax)": [[2, "src.activation.Softmax.zero_grad"]], "zero_grad() (m\u00e9thode src.activation.softplus)": [[2, "src.activation.Softplus.zero_grad"]], "zero_grad() (m\u00e9thode src.activation.stablesigmoid)": [[2, "src.activation.StableSigmoid.zero_grad"]], "zero_grad() (m\u00e9thode src.activation.tanh)": [[2, "src.activation.TanH.zero_grad"]], "zero_grad() (m\u00e9thode src.convolution.avgpool1d)": [[2, "src.convolution.AvgPool1D.zero_grad"]], "zero_grad() (m\u00e9thode src.convolution.conv1d)": [[2, "src.convolution.Conv1D.zero_grad"]], "zero_grad() (m\u00e9thode src.convolution.flatten)": [[2, "src.convolution.Flatten.zero_grad"]], "zero_grad() (m\u00e9thode src.convolution.maxpool1d)": [[2, "src.convolution.MaxPool1D.zero_grad"]], "zero_grad() (m\u00e9thode src.encapsulation.sequential)": [[2, "src.encapsulation.Sequential.zero_grad"]], "zero_grad() (m\u00e9thode src.linear.linear)": [[2, "src.linear.Linear.zero_grad"]], "zero_grad() (m\u00e9thode src.module.module)": [[2, "src.module.Module.zero_grad"]]}})