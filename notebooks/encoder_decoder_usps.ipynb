{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.linear import Linear\n",
    "from src.loss import *\n",
    "from src.activation import TanH, Sigmoid, StableSigmoid, Softmax, LogSoftmax, ReLU, TanH, Softplus\n",
    "from src.encapsulation import Sequential, Optim\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.mltools import *\n",
    "\n",
    "def normalize_batch_image(X):\n",
    "    mn = np.min(X)\n",
    "    mx = np.max(X)\n",
    "    X_norm = (X - mn) * (1.0 / (mx - mn))\n",
    "    return X_norm\n",
    "\n",
    "def load_usps(fn):\n",
    "    with open(fn, \"r\") as f:\n",
    "        f.readline()\n",
    "        data = [[float(X) for X in l.split()] for l in f if len(l.split()) > 2]\n",
    "    tmp = np.array(data)\n",
    "    return normalize_batch_image(tmp[:, 1:]), tmp[:, 0].astype(int)\n",
    "\n",
    "\n",
    "X_train, y_train = load_usps(\"data/USPS_train.txt\")\n",
    "X_test, y_test = load_usps(\"data/USPS_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "encoder = [\n",
    "    Linear(256, 64),\n",
    "    TanH(),\n",
    "]\n",
    "decoder = [\n",
    "    Linear(64, 256),\n",
    "    Sigmoid()\n",
    "]\n",
    "net_usps = Sequential(*(encoder + decoder))\n",
    "optimizer = Optim(net_usps.reset(), BCELoss(), eps=1e-3)\n",
    "result_df = optimizer.SGD_eval(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    batch_size,\n",
    "    100,\n",
    "    test_size=0.33,\n",
    "    return_dataframe=True,\n",
    "    online_plot=True,\n",
    "    patience=None,\n",
    ")\n",
    "\n",
    "loss_long_df = pd.melt(\n",
    "    result_df,\n",
    "    id_vars=\"epoch\",\n",
    "    value_vars=[\"loss_test\", \"loss_train\"],\n",
    "    value_name=\"loss\",\n",
    "    var_name=\"during\",\n",
    ").replace({\"loss_test\": \"test\", \"loss_train\": \"train\"})\n",
    "sns.lineplot(data=loss_long_df, x=\"epoch\", y=\"loss\", hue=\"during\", ax=ax)\n",
    "\n",
    "n = 10\n",
    "decoded_imgs = net_usps.forward(X_test)\n",
    "plt.figure(figsize=(20, 4))\n",
    "fig.set_tight_layout(True)\n",
    "\n",
    "for i in range(n):\n",
    "    # find first class of type i\n",
    "    idx = np.nonzero(y_test==i)[0][0]\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[idx].reshape(16, 16))\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[idx].reshape(16, 16))\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "with open(\"./notebooks/mnist_100_epoch_simple_net.pkl\", \"wb\") as f:\n",
    "    pickle.dump(optimizer, f)\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
