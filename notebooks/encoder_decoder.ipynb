{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/mnt/48566869-e5b1-482e-907d-2c513d1afe25/Documents/NeuralNetworksDIY\n"
     ]
    }
   ],
   "source": [
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "from src.linear import Linear\n",
    "from src.loss import MSELoss, CrossEntropyLoss, BCELoss, CELogSoftmax\n",
    "from src.activation import TanH, Sigmoid, Softmax\n",
    "from src.encapsulation import Sequential, Optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jouer avec les hpyerparam\n",
    "espace latent\n",
    "les initialisation \n",
    "plein de loss \n",
    "qu'est ce qui boost les perfs "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Débruitage d'image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset : https://www.kaggle.com/datasets/uurdeep/cleaning-dirty-documents-unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root_dir):\n",
    "    size = (540, 420)\n",
    "    X = []\n",
    "    for filepath in os.listdir(root_dir+'/X'):\n",
    "        imgpath = os.path.join(root_dir, \"X\", filepath)\n",
    "        image = io.imread(imgpath)\n",
    "        image = transform.resize(image, size).flatten()\n",
    "        X.append(image)\n",
    "    X = np.array(X)\n",
    "    \n",
    "    y = []\n",
    "    for filepath in os.listdir(root_dir+'/y'):\n",
    "        imgpath = os.path.join(root_dir, \"y\", filepath)\n",
    "        image = io.imread(imgpath)\n",
    "        image = transform.resize(image, size).flatten()\n",
    "        y.append(image)\n",
    "    y = np.array(y)\n",
    "    \n",
    "    return X, y\n",
    "X, y = load_data(\"./data/dirty_documents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(144, 226800)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/10 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'forward'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m net \u001b[39m=\u001b[39m encoder \u001b[39m+\u001b[39m decoder\n\u001b[1;32m     17\u001b[0m optimizer \u001b[39m=\u001b[39m Optim(net, CrossEntropyLoss(), eps\u001b[39m=\u001b[39m\u001b[39m1e-1\u001b[39m)\n\u001b[0;32m---> 18\u001b[0m lossList \u001b[39m=\u001b[39m optimizer\u001b[39m.\u001b[39;49mSGD(X, y, batch_size, \u001b[39m10\u001b[39;49m)\n\u001b[1;32m     19\u001b[0m \u001b[39mprint\u001b[39m(lossList)\n\u001b[1;32m     20\u001b[0m pd\u001b[39m.\u001b[39mSeries(lossList)\u001b[39m.\u001b[39mplot()\n",
      "File \u001b[0;32m/mnt/48566869-e5b1-482e-907d-2c513d1afe25/Documents/NeuralNetworksDIY/src/encapsulation.py:128\u001b[0m, in \u001b[0;36mOptim.SGD\u001b[0;34m(self, X, y, batch_size, epoch, network, shuffle)\u001b[0m\n\u001b[1;32m    126\u001b[0m loss_sum \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    127\u001b[0m \u001b[39mfor\u001b[39;00m X_i, y_i \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(batch_X, batch_Y):\n\u001b[0;32m--> 128\u001b[0m     loss_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstep(X_i, y_i)\u001b[39m.\u001b[39msum()\n\u001b[1;32m    129\u001b[0m loss_list\u001b[39m.\u001b[39mappend(loss_sum \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(y))\n\u001b[1;32m    130\u001b[0m \u001b[39m# print(f\"loss = {loss_list[-1]}\")\u001b[39;00m\n",
      "File \u001b[0;32m/mnt/48566869-e5b1-482e-907d-2c513d1afe25/Documents/NeuralNetworksDIY/src/encapsulation.py:92\u001b[0m, in \u001b[0;36mOptim.step\u001b[0;34m(self, batch_x, batch_y)\u001b[0m\n\u001b[1;32m     89\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mstep\u001b[39m(\u001b[39mself\u001b[39m, batch_x, batch_y):\n\u001b[1;32m     90\u001b[0m     \u001b[39m# y_hat = self.network.forward(batch_x).reshape(-1, 1)  # (batchsize, 1)\u001b[39;00m\n\u001b[1;32m     91\u001b[0m     \u001b[39m# Il faut fix ce reshape, il broke en multiclass en reshapant de (batchsize=8, 2 class) => (16, 1)\u001b[39;00m\n\u001b[0;32m---> 92\u001b[0m     y_hat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mnetwork\u001b[39m.\u001b[39;49mforward(batch_x)\n\u001b[1;32m     93\u001b[0m     loss_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mforward(batch_y, y_hat)\n\u001b[1;32m     94\u001b[0m     loss_delta \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mloss\u001b[39m.\u001b[39mbackward(batch_y, y_hat)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'forward'"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "d = 2  # Dim des entrées\n",
    "\n",
    "X = np.random.random(size=(256, d))\n",
    "y = np.random.choice([1], size=(256, 1))\n",
    "\n",
    "encoder = [\n",
    "    Linear(2, 2),\n",
    "    TanH(),\n",
    "    Linear(2, 1),\n",
    "    Sigmoid(),\n",
    "]\n",
    "decoder = [\n",
    "    \n",
    "]\n",
    "net = encoder + decoder\n",
    "optimizer = Optim(net, CrossEntropyLoss(), eps=1e-1)\n",
    "lossList = optimizer.SGD(X, y, batch_size, 10)\n",
    "print(lossList)\n",
    "pd.Series(lossList).plot()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
