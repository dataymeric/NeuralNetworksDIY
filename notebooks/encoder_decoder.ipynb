{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%cd ..\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from src.linear import Linear\n",
    "from src.loss import *\n",
    "from src.activation import TanH, Sigmoid, StableSigmoid, Softmax, LogSoftmax, ReLU, LeakyReLU, Softplus\n",
    "from src.encapsulation import Sequential, Optim\n",
    "\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "jouer avec les hpyerparam\n",
    "espace latent\n",
    "les initialisation \n",
    "plein de loss \n",
    "qu'est ce qui boost les perfs "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DÃ©bruitage d'image plus petite"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "fashion mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(rootdir, class_list=None, trim: float = 0.5):\n",
    "    def normalize_batch_image(X):\n",
    "        mn = np.min(X)\n",
    "        mx = np.max(X)\n",
    "        X_norm = (X - mn) * (1.0 / (mx - mn))\n",
    "        return X_norm\n",
    "\n",
    "    train = pd.read_csv(os.path.join(rootdir, \"fashion-mnist_train.csv\"))\n",
    "    # Filtering requested class\n",
    "    if class_list:\n",
    "        train = train[train[\"label\"].isin(class_list)]\n",
    "    y_train = train[\"label\"].values\n",
    "    X_train = train.drop(columns=\"label\").values\n",
    "\n",
    "    test = pd.read_csv(os.path.join(rootdir, \"fashion-mnist_test.csv\"))\n",
    "    # Filtering requested class\n",
    "    if class_list:\n",
    "        test = test[test[\"label\"].isin(class_list)]\n",
    "    y_test = test[\"label\"].values\n",
    "    X_test = test.drop(columns=\"label\").values\n",
    "\n",
    "    trim_train = int(len(X_train) * trim)\n",
    "    # trim_test = int(len(X_test) * trim)\n",
    "    trim_test = int(len(X_test))\n",
    "\n",
    "    # Normalization + trimming\n",
    "    X_train = normalize_batch_image(X_train[:trim_train, :])\n",
    "    X_test = normalize_batch_image(X_test[:trim_test, :])\n",
    "    y_train = y_train[:trim_train]\n",
    "    y_test = y_test[:trim_test]\n",
    "\n",
    "    return (X_train, X_test, y_train, y_test)\n",
    "\n",
    "\n",
    "rootdir = \"./data/fashion-mnist/\"\n",
    "X_train, X_test, y_train, y_test = load_data(rootdir, [0], trim=0.5)\n",
    "\n",
    "y_train_oh = OneHotEncoder().fit_transform(y_train.reshape(-1, 1)).toarray()\n",
    "y_test_oh = OneHotEncoder().fit_transform(y_test.reshape(-1, 1)).toarray()\n",
    "nb_class = y_train_oh.shape[1]\n",
    "batch_size = 64\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "reconstruction simple "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "encoder = [\n",
    "    Linear(784, 64),\n",
    "    TanH(),\n",
    "]\n",
    "decoder = [\n",
    "    Linear(64, 784),\n",
    "    Sigmoid()\n",
    "]\n",
    "net = Sequential(*(encoder + decoder))\n",
    "optimizer = Optim(net.reset(), MSELoss(), eps=1e-3)\n",
    "result_df = optimizer.SGD_eval(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    batch_size,\n",
    "    50,\n",
    "    test_size=0.33,\n",
    "    return_dataframe=True,\n",
    "    online_plot=True,\n",
    ")\n",
    "\n",
    "loss_long_df = pd.melt(\n",
    "    result_df,\n",
    "    id_vars=\"epoch\",\n",
    "    value_vars=[\"loss_test\", \"loss_train\"],\n",
    "    value_name=\"loss\",\n",
    "    var_name=\"during\",\n",
    ").replace({\"loss_test\": \"test\", \"loss_train\": \"train\"})\n",
    "sns.lineplot(data=loss_long_df, x=\"epoch\", y=\"loss\", hue=\"during\", ax=ax)\n",
    "\n",
    "n = 10\n",
    "decoded_imgs = net.forward(X_test)\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruction par epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "fig.set_tight_layout(True)\n",
    "optimizer.network.reset()\n",
    "n = 10\n",
    "for i in range(n):\n",
    "    optimizer.SGD(\n",
    "        X_train,\n",
    "        X_train,\n",
    "        batch_size,\n",
    "        20,\n",
    "    )\n",
    "    decoded_imgs = optimizer.network.forward(X_test)\n",
    "\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[4].reshape(28, 28))\n",
    "    plt.title(f\"epoch {(i+1)*20}\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[4].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "fig.savefig('reports/src/reconstruction_per_epoch.pdf',\n",
    "            dpi=100, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data(rootdir, trim=0.5)\n",
    "optimizer = Optim(net.reset(), MSELoss(), eps=1e-3)\n",
    "optimizer.network.reset()\n",
    "optimizer.SGD(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    batch_size,\n",
    "    1000,\n",
    ")\n",
    "\n",
    "n = 10\n",
    "decoded_imgs = net.forward(X_test)\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "fig.savefig('reports/src/reconstruction_all_class.pdf', dpi=600)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does the middle activation funct impact reconstruction performance ? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(ncols=8, nrows=3, figsize=(43, 20))\n",
    "fig.set_tight_layout(True)\n",
    "for i, act_func in enumerate([TanH, Sigmoid, StableSigmoid, Softmax, LogSoftmax, ReLU, LeakyReLU, Softplus]):\n",
    "    try:\n",
    "        ax_col = ax[:, i]\n",
    "        ax_col[0].set_title(act_func.__name__)\n",
    "\n",
    "        encoder = [\n",
    "            Linear(784, 64),\n",
    "            act_func(),\n",
    "        ]\n",
    "        decoder = [\n",
    "            Linear(64, 784),\n",
    "            Sigmoid()\n",
    "        ]\n",
    "        net = Sequential(*(encoder + decoder))\n",
    "        optimizer = Optim(net.reset(), MSELoss(), eps=1e-3)\n",
    "        result_df = optimizer.SGD_eval(\n",
    "            X_train,\n",
    "            X_train,\n",
    "            batch_size,\n",
    "            50,\n",
    "            test_size=0.33,\n",
    "            return_dataframe=True,\n",
    "        )\n",
    "\n",
    "        loss_long_df = pd.melt(result_df, id_vars='epoch', value_vars=[\n",
    "                               'loss_test', 'loss_train'], value_name='loss', var_name='during').replace({'loss_test': 'test', 'loss_train': 'train'})\n",
    "        sns.lineplot(loss_long_df, x='epoch', y='loss',\n",
    "                     hue='during', ax=ax_col[0])\n",
    "        # display original\n",
    "        ax_col[1].imshow(X_test[i].reshape(28, 28), cmap='gist_gray')\n",
    "        # ax_col[1].set_title(\"original\")\n",
    "        ax_col[1].get_xaxis().set_visible(False)\n",
    "        ax_col[1].get_yaxis().set_visible(False)\n",
    "\n",
    "        # display reconstruction\n",
    "        ax_col[2].imshow(decoded_imgs[i].reshape(28, 28), cmap='gist_gray')\n",
    "        # ax_col[2].set_title(\"reconstructed\")\n",
    "        ax_col[2].get_xaxis().set_visible(False)\n",
    "        ax_col[2].get_yaxis().set_visible(False)\n",
    "    except KeyError:\n",
    "        continue\n",
    "fig.savefig('reports/src/encoder_decoder_middle_func_simple_net.pdf',\n",
    "            dpi=100, bbox_inches=\"tight\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RÃ©seau plus complexe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots()\n",
    "\n",
    "encoder = [\n",
    "    Linear(784, 256),\n",
    "    TanH(),\n",
    "    Linear(256, 64),\n",
    "]\n",
    "decoder = [\n",
    "    Linear(64, 256),\n",
    "    TanH(),\n",
    "    Linear(256, 784),\n",
    "    Sigmoid()\n",
    "]\n",
    "net = Sequential(*(encoder + decoder))\n",
    "optimizer = Optim(net.reset(), MSELoss(), eps=1e-3)\n",
    "result_df = optimizer.SGD_eval(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    batch_size,\n",
    "    50,\n",
    "    test_size=0.33,\n",
    "    return_dataframe=True,\n",
    "    online_plot=True,\n",
    ")\n",
    "\n",
    "loss_long_df = pd.melt(\n",
    "    result_df,\n",
    "    id_vars=\"epoch\",\n",
    "    value_vars=[\"loss_test\", \"loss_train\"],\n",
    "    value_name=\"loss\",\n",
    "    var_name=\"during\",\n",
    ").replace({\"loss_test\": \"test\", \"loss_train\": \"train\"})\n",
    "sns.lineplot(data=loss_long_df, x=\"epoch\", y=\"loss\", hue=\"during\", ax=ax)\n",
    "\n",
    "n = 10\n",
    "decoded_imgs = net.forward(X_test)\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "with open(\"./notebooks/fashion-mnist_1000_epoch_simple_net.pkl\", \"wb\") as f:\n",
    "    pickle.dump(optimizer.network, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20, 4))\n",
    "optimizer.network.reset()\n",
    "n = 10\n",
    "for i in range(n):\n",
    "    optimizer.SGD(\n",
    "        X_train,\n",
    "        X_train,\n",
    "        batch_size,\n",
    "        20,\n",
    "    )\n",
    "    decoded_imgs = optimizer.network.forward(X_test)\n",
    "\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[4].reshape(28, 28))\n",
    "    plt.title(f\"epoch {(i+1)*20}\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[4].reshape(28, 28))\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "fig.savefig('reports/src/reconstruction_per_epoch.pdf', dpi=600)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = load_data(rootdir, trim=0.5)\n",
    "optimizer = Optim(net.reset(), MSELoss(), eps=1e-3)\n",
    "optimizer.network.reset()\n",
    "optimizer.SGD(\n",
    "    X_train,\n",
    "    X_train,\n",
    "    batch_size,\n",
    "    250,\n",
    ")\n",
    "\n",
    "n = 10\n",
    "decoded_imgs = net.forward(X_test)\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(n):\n",
    "    # display original\n",
    "    ax = plt.subplot(2, n, i + 1)\n",
    "    plt.imshow(X_test[i].reshape(28, 28))\n",
    "    plt.title(\"original\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "\n",
    "    # display reconstruction\n",
    "    ax = plt.subplot(2, n, i + 1 + n)\n",
    "    plt.imshow(decoded_imgs[i].reshape(28, 28))\n",
    "    plt.title(\"reconstructed\")\n",
    "    plt.gray()\n",
    "    ax.get_xaxis().set_visible(False)\n",
    "    ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "fig.savefig('reports/src/reconstruction_all_class.pdf', dpi=600)\n",
    "with open(\"./notebooks/fashion-mnist_1000_epoch_complex_net.pkl\", \"wb\") as f:\n",
    "    pickle.dump(optimizer.network, f)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DÃ©bruitage d'image"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dataset : https://www.kaggle.com/datasets/uurdeep/cleaning-dirty-documents-unzipped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(root_dir):\n",
    "    size = (540, 420)\n",
    "    X = []\n",
    "    for filepath in os.listdir(root_dir + \"/X\"):\n",
    "        imgpath = os.path.join(root_dir, \"X\", filepath)\n",
    "        image = io.imread(imgpath)\n",
    "        image = transform.resize(image, size).flatten()\n",
    "        X.append(image)\n",
    "    X = np.array(X)\n",
    "\n",
    "    y = []\n",
    "    for filepath in os.listdir(root_dir + \"/y\"):\n",
    "        imgpath = os.path.join(root_dir, \"y\", filepath)\n",
    "        image = io.imread(imgpath)\n",
    "        image = transform.resize(image, size).flatten()\n",
    "        y.append(image)\n",
    "    y = np.array(y)\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "X, y = load_data(\"./data/dirty_documents\")\n",
    "print(X.shape)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.convolution import *\n",
    "\n",
    "encoder = [Conv1D(3, 1, 16, stride=2), TanH(),\n",
    "           Conv1D(3, 1, 8, stride=2), TanH()]\n",
    "\n",
    "decoder = [\n",
    "    Conv1D(3, 1, 8, stride=2),\n",
    "    TanH(),\n",
    "    Conv1D(3, 1, 16, 2),\n",
    "    TanH(),\n",
    "    Conv1D(3, 1, 1),\n",
    "    Sigmoid(),\n",
    "]\n",
    "\n",
    "\n",
    "net = Sequential(*(encoder + decoder))\n",
    "optimizer = Optim(net, MSELoss(), eps=1e-1)\n",
    "lossList = optimizer.SGD(X[:, :, np.newaxis], y, 144, 10)\n",
    "print(lossList)\n",
    "pd.Series(lossList).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "d = 2  # Dim des entrÃ©es\n",
    "\n",
    "X = np.random.random(size=(256, d))\n",
    "y = np.random.choice([1], size=(256, 1))\n",
    "\n",
    "encoder = [\n",
    "    Linear(226800, 226800 // 8),\n",
    "    TanH(),\n",
    "    Linear(226800 // 8, 226800 / 16),\n",
    "    TanH(),\n",
    "    Linear(226800 / 16, 226800 / 32),\n",
    "    TanH(),\n",
    "]\n",
    "decoder = [\n",
    "    Linear(226800 / 16, 226800 / 32),\n",
    "    TanH(),\n",
    "    Linear(226800 / 8, 226800 / 16),\n",
    "    TanH(),\n",
    "    Linear(226800, 226800 / 8),\n",
    "    Sigmoid(),\n",
    "]\n",
    "net = encoder + decoder\n",
    "optimizer = Optim(net, CrossEntropyLoss(), eps=1e-1)\n",
    "lossList = optimizer.SGD(X, y, batch_size, 10)\n",
    "print(lossList)\n",
    "pd.Series(lossList).plot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**A faire avec une convolution**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
